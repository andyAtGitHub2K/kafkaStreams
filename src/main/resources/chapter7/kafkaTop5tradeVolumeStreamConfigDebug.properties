# properties file for Stock Transaction App Exposing Kafka Metrics in Debug mode
application.id=kafka_metrics_trade_volume_id
group.id=kafka_metrics_KStreamVsKTableTV-group
client.id=kafka_metrics_KStreamVsKTableTV-client
auto.offset.reset=latest
auto.commit.interval.ms=30000
commit.interval.ms=10000
bootstrap.servers=localhost:9092
num.stream.threads=1
metadata.max.age.ms=10000
default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
default.value.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
replication.factor=1
default.timestamp.extractor=org.apache.kafka.streams.processor.WallclockTimestampExtractor
cache.max.bytes.buffering=100000
state.dir=/tmp/kafka-streams
metrics.recording.level=DEBUG
# list topic
# ./bin/kafka-topics.sh --list --zookeeper localhost:2181

# create topic
# ./bin/kafka-topics.sh --create  --zookeeper localhost:2181/kafka --replication-factor 1 --partitions 1 --topic test

# publish a message
# ./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic

# consume messages

#  ./kafka-topics.sh --create  --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic "share-volume-stream"

#  ./kafka-topics.sh --create  --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic "stock-volume-by-industry"

# ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic stock-volume-by-industry --from-beginning